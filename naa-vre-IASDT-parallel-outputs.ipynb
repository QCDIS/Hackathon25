{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Streaming Invasive Alien Species Digital Twin Outputs\n",
    "\n",
    "**Author**: [Taimur Khan](https://www.ufz.de/index.php?en=49404), Helmholtz Centre for Environmental Research - UFZ, Germany\n",
    "\n",
    "**Date**: 2025-02-20\n",
    "\n",
    "## Purpose\n",
    "\n",
    "The purpose of this notebook is to demonstrate how to stream the outputs of the Invasive Alien Species Digital Twin from the [BioDT OPenDAP service](http://opendap.biodt.eu). The outputs are streamed in real-time using `rioxarray` and visualized using the `matplotlib` library.\n",
    "\n",
    "The notebook has been parameterized using Jupyter Widgets to allow the user to select the desired habitat, climate model, climate scenario, and time period parameters for querying the desired dataset. \n",
    "\n",
    "The notebook is divided into the following sections:\n",
    "- [1. Import Libraries](#1.-Import-Libraries)\n",
    "- [2. Define Parameters](#2.-Define-Parameters)\n",
    "- [3. Query URL](#3.-Query-Data)\n",
    "- [4. Stream Data](#4.-Stream-Data)\n",
    "- [5. Visualize Data](#5.-Visualize-Data)\n",
    "- [6. Download Data (optional)](#6.-Download)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not have the required libraries installed, you can install them by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rioxarray matplotlib pandas matplotlib_scalebar ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otherwise just import the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import rioxarray\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.animation as animation\n",
    "import os\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Habitat Abbreviation: 12a\n"
     ]
    }
   ],
   "source": [
    "# A-Selecte Habitat\n",
    "url = \"http://opendap.biodt.eu/ias-pdt/0/outputs/key.csv\"\n",
    "df_hab = pd.read_csv(url)\n",
    "\n",
    "# Get the corresponding value for hab_abb for the selected hab_name\n",
    "selected_hab_abb = '1'\n",
    "conf_data_path = '/tmp/data/'\n",
    "\n",
    "\n",
    "\n",
    "folder_path = None\n",
    "tif_url = None\n",
    "download_path = None\n",
    "\n",
    "\n",
    "param_habitat_name =  'Ruderal habitats'\n",
    "habitat_type = param_habitat_name.replace(' ','_').lower()\n",
    "selected_hab_abb = str(df_hab[df_hab[\"hab_name\"] == habitat_type][\"hab_abb\"].values[0])\n",
    "param_climate_model = 'IPSL-CM6A-LR'\n",
    "param_species_class = 'Liliopsida'\n",
    "\n",
    "\n",
    "conf_x =  0.95\n",
    "conf_y =  0.95\n",
    "conf_arrow_length = 0.1\n",
    "print(f\"Selected Habitat Abbreviation: {selected_hab_abb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Query URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hab_abb</th>\n",
       "      <th>hab_name</th>\n",
       "      <th>time_period</th>\n",
       "      <th>climate_model</th>\n",
       "      <th>climate_scenario</th>\n",
       "      <th>ias_id</th>\n",
       "      <th>taxon_name</th>\n",
       "      <th>species_name</th>\n",
       "      <th>class</th>\n",
       "      <th>order</th>\n",
       "      <th>family</th>\n",
       "      <th>tif_path_mean</th>\n",
       "      <th>tif_path_sd</th>\n",
       "      <th>tif_path_cov</th>\n",
       "      <th>tif_path_anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12a</td>\n",
       "      <td>Ruderal habitats</td>\n",
       "      <td>1981-2010</td>\n",
       "      <td>Current</td>\n",
       "      <td>Current</td>\n",
       "      <td>SR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Current/SR_mean.tif</td>\n",
       "      <td>Current/SR_sd.tif</td>\n",
       "      <td>Current/SR_cov.tif</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12a</td>\n",
       "      <td>Ruderal habitats</td>\n",
       "      <td>1981-2010</td>\n",
       "      <td>Current</td>\n",
       "      <td>Current</td>\n",
       "      <td>Sp_0001</td>\n",
       "      <td>Acorus calamus L.</td>\n",
       "      <td>Acorus calamus</td>\n",
       "      <td>Liliopsida</td>\n",
       "      <td>Acorales</td>\n",
       "      <td>Acoraceae</td>\n",
       "      <td>Current/Sp_0001_mean.tif</td>\n",
       "      <td>Current/Sp_0001_sd.tif</td>\n",
       "      <td>Current/Sp_0001_cov.tif</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12a</td>\n",
       "      <td>Ruderal habitats</td>\n",
       "      <td>1981-2010</td>\n",
       "      <td>Current</td>\n",
       "      <td>Current</td>\n",
       "      <td>Sp_0007</td>\n",
       "      <td>Lysichiton americanus Hultén &amp; H.St.John</td>\n",
       "      <td>Lysichiton americanus</td>\n",
       "      <td>Liliopsida</td>\n",
       "      <td>Alismatales</td>\n",
       "      <td>Araceae</td>\n",
       "      <td>Current/Sp_0007_mean.tif</td>\n",
       "      <td>Current/Sp_0007_sd.tif</td>\n",
       "      <td>Current/Sp_0007_cov.tif</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12a</td>\n",
       "      <td>Ruderal habitats</td>\n",
       "      <td>1981-2010</td>\n",
       "      <td>Current</td>\n",
       "      <td>Current</td>\n",
       "      <td>Sp_0011</td>\n",
       "      <td>Zantedeschia aethiopica (L.) Spreng.</td>\n",
       "      <td>Zantedeschia aethiopica</td>\n",
       "      <td>Liliopsida</td>\n",
       "      <td>Alismatales</td>\n",
       "      <td>Araceae</td>\n",
       "      <td>Current/Sp_0011_mean.tif</td>\n",
       "      <td>Current/Sp_0011_sd.tif</td>\n",
       "      <td>Current/Sp_0011_cov.tif</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12a</td>\n",
       "      <td>Ruderal habitats</td>\n",
       "      <td>1981-2010</td>\n",
       "      <td>Current</td>\n",
       "      <td>Current</td>\n",
       "      <td>Sp_0012</td>\n",
       "      <td>Phoenix dactylifera L.</td>\n",
       "      <td>Phoenix dactylifera</td>\n",
       "      <td>Liliopsida</td>\n",
       "      <td>Arecales</td>\n",
       "      <td>Arecaceae</td>\n",
       "      <td>Current/Sp_0012_mean.tif</td>\n",
       "      <td>Current/Sp_0012_sd.tif</td>\n",
       "      <td>Current/Sp_0012_cov.tif</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20281</th>\n",
       "      <td>12a</td>\n",
       "      <td>Ruderal habitats</td>\n",
       "      <td>2071-2100</td>\n",
       "      <td>UKESM1-0-LL</td>\n",
       "      <td>ssp585</td>\n",
       "      <td>Sp_1320</td>\n",
       "      <td>Tsuga canadensis (L.) Carrière</td>\n",
       "      <td>Tsuga canadensis</td>\n",
       "      <td>Pinopsida</td>\n",
       "      <td>Pinales</td>\n",
       "      <td>Pinaceae</td>\n",
       "      <td>2071_2100_ssp585_UKESM1_0_LL/Sp_1320_mean.tif</td>\n",
       "      <td>2071_2100_ssp585_UKESM1_0_LL/Sp_1320_sd.tif</td>\n",
       "      <td>2071_2100_ssp585_UKESM1_0_LL/Sp_1320_cov.tif</td>\n",
       "      <td>2071_2100_ssp585_UKESM1_0_LL/Sp_1320_anomaly.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20282</th>\n",
       "      <td>12a</td>\n",
       "      <td>Ruderal habitats</td>\n",
       "      <td>2071-2100</td>\n",
       "      <td>UKESM1-0-LL</td>\n",
       "      <td>ssp585</td>\n",
       "      <td>Sp_1321</td>\n",
       "      <td>Tsuga heterophylla (Raf.) Sarg.</td>\n",
       "      <td>Tsuga heterophylla</td>\n",
       "      <td>Pinopsida</td>\n",
       "      <td>Pinales</td>\n",
       "      <td>Pinaceae</td>\n",
       "      <td>2071_2100_ssp585_UKESM1_0_LL/Sp_1321_mean.tif</td>\n",
       "      <td>2071_2100_ssp585_UKESM1_0_LL/Sp_1321_sd.tif</td>\n",
       "      <td>2071_2100_ssp585_UKESM1_0_LL/Sp_1321_cov.tif</td>\n",
       "      <td>2071_2100_ssp585_UKESM1_0_LL/Sp_1321_anomaly.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20283</th>\n",
       "      <td>12a</td>\n",
       "      <td>Ruderal habitats</td>\n",
       "      <td>2071-2100</td>\n",
       "      <td>UKESM1-0-LL</td>\n",
       "      <td>ssp585</td>\n",
       "      <td>Sp_1328</td>\n",
       "      <td>Cyrtomium falcatum (L.fil.) C.Presl</td>\n",
       "      <td>Cyrtomium falcatum</td>\n",
       "      <td>Polypodiopsida</td>\n",
       "      <td>Polypodiales</td>\n",
       "      <td>Dryopteridaceae</td>\n",
       "      <td>2071_2100_ssp585_UKESM1_0_LL/Sp_1328_mean.tif</td>\n",
       "      <td>2071_2100_ssp585_UKESM1_0_LL/Sp_1328_sd.tif</td>\n",
       "      <td>2071_2100_ssp585_UKESM1_0_LL/Sp_1328_cov.tif</td>\n",
       "      <td>2071_2100_ssp585_UKESM1_0_LL/Sp_1328_anomaly.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20284</th>\n",
       "      <td>12a</td>\n",
       "      <td>Ruderal habitats</td>\n",
       "      <td>2071-2100</td>\n",
       "      <td>UKESM1-0-LL</td>\n",
       "      <td>ssp585</td>\n",
       "      <td>Sp_1329</td>\n",
       "      <td>Cyrtomium fortunei J.Sm.</td>\n",
       "      <td>Cyrtomium fortunei</td>\n",
       "      <td>Polypodiopsida</td>\n",
       "      <td>Polypodiales</td>\n",
       "      <td>Dryopteridaceae</td>\n",
       "      <td>2071_2100_ssp585_UKESM1_0_LL/Sp_1329_mean.tif</td>\n",
       "      <td>2071_2100_ssp585_UKESM1_0_LL/Sp_1329_sd.tif</td>\n",
       "      <td>2071_2100_ssp585_UKESM1_0_LL/Sp_1329_cov.tif</td>\n",
       "      <td>2071_2100_ssp585_UKESM1_0_LL/Sp_1329_anomaly.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20285</th>\n",
       "      <td>12a</td>\n",
       "      <td>Ruderal habitats</td>\n",
       "      <td>2071-2100</td>\n",
       "      <td>UKESM1-0-LL</td>\n",
       "      <td>ssp585</td>\n",
       "      <td>Sp_1333</td>\n",
       "      <td>Onoclea sensibilis L.</td>\n",
       "      <td>Onoclea sensibilis</td>\n",
       "      <td>Polypodiopsida</td>\n",
       "      <td>Polypodiales</td>\n",
       "      <td>Onocleaceae</td>\n",
       "      <td>2071_2100_ssp585_UKESM1_0_LL/Sp_1333_mean.tif</td>\n",
       "      <td>2071_2100_ssp585_UKESM1_0_LL/Sp_1333_sd.tif</td>\n",
       "      <td>2071_2100_ssp585_UKESM1_0_LL/Sp_1333_cov.tif</td>\n",
       "      <td>2071_2100_ssp585_UKESM1_0_LL/Sp_1333_anomaly.tif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20286 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hab_abb          hab_name time_period climate_model climate_scenario  \\\n",
       "0         12a  Ruderal habitats   1981-2010       Current          Current   \n",
       "1         12a  Ruderal habitats   1981-2010       Current          Current   \n",
       "2         12a  Ruderal habitats   1981-2010       Current          Current   \n",
       "3         12a  Ruderal habitats   1981-2010       Current          Current   \n",
       "4         12a  Ruderal habitats   1981-2010       Current          Current   \n",
       "...       ...               ...         ...           ...              ...   \n",
       "20281     12a  Ruderal habitats   2071-2100   UKESM1-0-LL           ssp585   \n",
       "20282     12a  Ruderal habitats   2071-2100   UKESM1-0-LL           ssp585   \n",
       "20283     12a  Ruderal habitats   2071-2100   UKESM1-0-LL           ssp585   \n",
       "20284     12a  Ruderal habitats   2071-2100   UKESM1-0-LL           ssp585   \n",
       "20285     12a  Ruderal habitats   2071-2100   UKESM1-0-LL           ssp585   \n",
       "\n",
       "        ias_id                                taxon_name  \\\n",
       "0           SR                                       NaN   \n",
       "1      Sp_0001                         Acorus calamus L.   \n",
       "2      Sp_0007  Lysichiton americanus Hultén & H.St.John   \n",
       "3      Sp_0011      Zantedeschia aethiopica (L.) Spreng.   \n",
       "4      Sp_0012                    Phoenix dactylifera L.   \n",
       "...        ...                                       ...   \n",
       "20281  Sp_1320            Tsuga canadensis (L.) Carrière   \n",
       "20282  Sp_1321           Tsuga heterophylla (Raf.) Sarg.   \n",
       "20283  Sp_1328       Cyrtomium falcatum (L.fil.) C.Presl   \n",
       "20284  Sp_1329                  Cyrtomium fortunei J.Sm.   \n",
       "20285  Sp_1333                     Onoclea sensibilis L.   \n",
       "\n",
       "                  species_name           class         order           family  \\\n",
       "0                          NaN             NaN           NaN              NaN   \n",
       "1               Acorus calamus      Liliopsida      Acorales        Acoraceae   \n",
       "2        Lysichiton americanus      Liliopsida   Alismatales          Araceae   \n",
       "3      Zantedeschia aethiopica      Liliopsida   Alismatales          Araceae   \n",
       "4          Phoenix dactylifera      Liliopsida      Arecales        Arecaceae   \n",
       "...                        ...             ...           ...              ...   \n",
       "20281         Tsuga canadensis       Pinopsida       Pinales         Pinaceae   \n",
       "20282       Tsuga heterophylla       Pinopsida       Pinales         Pinaceae   \n",
       "20283       Cyrtomium falcatum  Polypodiopsida  Polypodiales  Dryopteridaceae   \n",
       "20284       Cyrtomium fortunei  Polypodiopsida  Polypodiales  Dryopteridaceae   \n",
       "20285       Onoclea sensibilis  Polypodiopsida  Polypodiales      Onocleaceae   \n",
       "\n",
       "                                       tif_path_mean  \\\n",
       "0                                Current/SR_mean.tif   \n",
       "1                           Current/Sp_0001_mean.tif   \n",
       "2                           Current/Sp_0007_mean.tif   \n",
       "3                           Current/Sp_0011_mean.tif   \n",
       "4                           Current/Sp_0012_mean.tif   \n",
       "...                                              ...   \n",
       "20281  2071_2100_ssp585_UKESM1_0_LL/Sp_1320_mean.tif   \n",
       "20282  2071_2100_ssp585_UKESM1_0_LL/Sp_1321_mean.tif   \n",
       "20283  2071_2100_ssp585_UKESM1_0_LL/Sp_1328_mean.tif   \n",
       "20284  2071_2100_ssp585_UKESM1_0_LL/Sp_1329_mean.tif   \n",
       "20285  2071_2100_ssp585_UKESM1_0_LL/Sp_1333_mean.tif   \n",
       "\n",
       "                                       tif_path_sd  \\\n",
       "0                                Current/SR_sd.tif   \n",
       "1                           Current/Sp_0001_sd.tif   \n",
       "2                           Current/Sp_0007_sd.tif   \n",
       "3                           Current/Sp_0011_sd.tif   \n",
       "4                           Current/Sp_0012_sd.tif   \n",
       "...                                            ...   \n",
       "20281  2071_2100_ssp585_UKESM1_0_LL/Sp_1320_sd.tif   \n",
       "20282  2071_2100_ssp585_UKESM1_0_LL/Sp_1321_sd.tif   \n",
       "20283  2071_2100_ssp585_UKESM1_0_LL/Sp_1328_sd.tif   \n",
       "20284  2071_2100_ssp585_UKESM1_0_LL/Sp_1329_sd.tif   \n",
       "20285  2071_2100_ssp585_UKESM1_0_LL/Sp_1333_sd.tif   \n",
       "\n",
       "                                       tif_path_cov  \\\n",
       "0                                Current/SR_cov.tif   \n",
       "1                           Current/Sp_0001_cov.tif   \n",
       "2                           Current/Sp_0007_cov.tif   \n",
       "3                           Current/Sp_0011_cov.tif   \n",
       "4                           Current/Sp_0012_cov.tif   \n",
       "...                                             ...   \n",
       "20281  2071_2100_ssp585_UKESM1_0_LL/Sp_1320_cov.tif   \n",
       "20282  2071_2100_ssp585_UKESM1_0_LL/Sp_1321_cov.tif   \n",
       "20283  2071_2100_ssp585_UKESM1_0_LL/Sp_1328_cov.tif   \n",
       "20284  2071_2100_ssp585_UKESM1_0_LL/Sp_1329_cov.tif   \n",
       "20285  2071_2100_ssp585_UKESM1_0_LL/Sp_1333_cov.tif   \n",
       "\n",
       "                                       tif_path_anomaly  \n",
       "0                                                   NaN  \n",
       "1                                                   NaN  \n",
       "2                                                   NaN  \n",
       "3                                                   NaN  \n",
       "4                                                   NaN  \n",
       "...                                                 ...  \n",
       "20281  2071_2100_ssp585_UKESM1_0_LL/Sp_1320_anomaly.tif  \n",
       "20282  2071_2100_ssp585_UKESM1_0_LL/Sp_1321_anomaly.tif  \n",
       "20283  2071_2100_ssp585_UKESM1_0_LL/Sp_1328_anomaly.tif  \n",
       "20284  2071_2100_ssp585_UKESM1_0_LL/Sp_1329_anomaly.tif  \n",
       "20285  2071_2100_ssp585_UKESM1_0_LL/Sp_1333_anomaly.tif  \n",
       "\n",
       "[20286 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# B-Query URL\n",
    "url_txt = f\"http://opendap.biodt.eu/ias-pdt/0/outputs/hab{selected_hab_abb}/predictions/Prediction_Summary_Shiny.txt\"\n",
    "df_mod = pd.read_csv(url_txt, sep=\"\\t\")\n",
    "display(df_mod)\n",
    "habitat_number = str(df_mod[df_mod[\"hab_name\"] == param_habitat_name][\"hab_abb\"].values[0] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 216 paths for 2011-2040 in /tmp/data/output_tif_groups/2011-2040/2011-2040_tif_paths.txt\n",
      "Saved 216 paths for 2041-2070 in /tmp/data/output_tif_groups/2041-2070/2041-2070_tif_paths.txt\n",
      "Saved 216 paths for 2071-2100 in /tmp/data/output_tif_groups/2071-2100/2071-2100_tif_paths.txt\n"
     ]
    }
   ],
   "source": [
    "# C1-paths-mean-query\n",
    "import shutil\n",
    "\n",
    "\n",
    "df_mod = pd.read_csv(url_txt, sep=\"\\t\")\n",
    "\n",
    "filtered_df = df_mod[\n",
    "    (df_mod[\"hab_abb\"] == habitat_number) &\n",
    "    (df_mod[\"climate_model\"] == param_climate_model) &\n",
    "    (df_mod[\"class\"] == param_species_class) \n",
    "]\n",
    "\n",
    "\n",
    "# display(filtered_df)\n",
    "\n",
    "grouped_tif_paths = filtered_df.groupby(\"time_period\")[\"tif_path_mean\"].agg(list).to_dict()\n",
    "\n",
    "# print(grouped_tif_paths)\n",
    "\n",
    "\n",
    "base_dir = conf_data_path+\"output_tif_groups\"\n",
    "shutil.rmtree(base_dir,ignore_errors=True)\n",
    "# Ensure base directory exists\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# Save each year's tif_path_mean array as a text file\n",
    "year_paths = []\n",
    "for year, paths in grouped_tif_paths.items():\n",
    "    year_dir = os.path.join(base_dir, str(year))  # Create a folder for each year\n",
    "    os.makedirs(year_dir, exist_ok=True)  # Ensure folder exists\n",
    "    year_paths.append(year_dir)\n",
    "    file_path = os.path.join(year_dir, f\"{year}_tif_paths.txt\")  # File name\n",
    "    with open(file_path, \"w\") as f:\n",
    "        for path in paths:\n",
    "            f.write(path + \"\\n\")  # Write each path on a new line\n",
    "\n",
    "    print(f\"Saved {len(paths)} paths for {year} in {file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/data/output_tif_groups/2011-2040/2011-2040_tif_paths.txt\n",
      "/tmp/data/output_tif_groups/2041-2070/2041-2070_tif_paths.txt\n"
     ]
    },
    {
     "ename": "ConnectTimeout",
     "evalue": "HTTPConnectionPool(host='opendap.biodt.eu', port=80): Max retries exceeded with url: /ias-pdt/0/outputs/hab12a/predictions/2041_2070_ssp370_IPSL_CM6A_LR/Sp_0261_mean.tif (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x741f3bdbd940>, 'Connection to opendap.biodt.eu timed out. (connect timeout=None)'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/envs/biodt-hackathon25/lib/python3.12/site-packages/urllib3/connection.py:198\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 198\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/envs/biodt-hackathon25/lib/python3.12/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/biodt-hackathon25/lib/python3.12/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mConnectTimeoutError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/envs/biodt-hackathon25/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/biodt-hackathon25/lib/python3.12/site-packages/urllib3/connectionpool.py:493\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 493\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/biodt-hackathon25/lib/python3.12/site-packages/urllib3/connection.py:445\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[0;32m--> 445\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/biodt-hackathon25/lib/python3.12/http/client.py:1333\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1333\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/biodt-hackathon25/lib/python3.12/http/client.py:1093\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1093\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1096\u001b[0m \n\u001b[1;32m   1097\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/biodt-hackathon25/lib/python3.12/http/client.py:1037\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m-> 1037\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/biodt-hackathon25/lib/python3.12/site-packages/urllib3/connection.py:276\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/biodt-hackathon25/lib/python3.12/site-packages/urllib3/connection.py:207\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m timed out. (connect timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    210\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mConnectTimeoutError\u001b[0m: (<urllib3.connection.HTTPConnection object at 0x741f3bdbd940>, 'Connection to opendap.biodt.eu timed out. (connect timeout=None)')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/envs/biodt-hackathon25/lib/python3.12/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/conda/envs/biodt-hackathon25/lib/python3.12/site-packages/urllib3/connectionpool.py:841\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    839\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 841\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m/opt/conda/envs/biodt-hackathon25/lib/python3.12/site-packages/urllib3/util/retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='opendap.biodt.eu', port=80): Max retries exceeded with url: /ias-pdt/0/outputs/hab12a/predictions/2041_2070_ssp370_IPSL_CM6A_LR/Sp_0261_mean.tif (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x741f3bdbd940>, 'Connection to opendap.biodt.eu timed out. (connect timeout=None)'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectTimeout\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 72\u001b[0m\n\u001b[1;32m     70\u001b[0m     mean_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://opendap.biodt.eu/ias-pdt/0/outputs/hab\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhabitat_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/predictions/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtif_path_mean\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m     tif_filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(year_path, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(mean_url))\n\u001b[0;32m---> 72\u001b[0m     downloaded_file \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_file_from_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtif_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m year \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(year_path)\n\u001b[1;32m     74\u001b[0m merged_output_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_merged_output.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m, in \u001b[0;36mdownload_file_from_url\u001b[0;34m(tif_url, download_path)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Function to download a file if it's a URL\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tif_url\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 10\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtif_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(download_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m out_file:\n",
      "File \u001b[0;32m/opt/conda/envs/biodt-hackathon25/lib/python3.12/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/biodt-hackathon25/lib/python3.12/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/biodt-hackathon25/lib/python3.12/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/conda/envs/biodt-hackathon25/lib/python3.12/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/conda/envs/biodt-hackathon25/lib/python3.12/site-packages/requests/adapters.py:688\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ConnectTimeoutError):\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, NewConnectionError):\n\u001b[0;32m--> 688\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeout(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ResponseError):\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RetryError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectTimeout\u001b[0m: HTTPConnectionPool(host='opendap.biodt.eu', port=80): Max retries exceeded with url: /ias-pdt/0/outputs/hab12a/predictions/2041_2070_ssp370_IPSL_CM6A_LR/Sp_0261_mean.tif (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x741f3bdbd940>, 'Connection to opendap.biodt.eu timed out. (connect timeout=None)'))"
     ]
    }
   ],
   "source": [
    "# D Merge_tif_files\n",
    "\n",
    "import os\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "\n",
    "def download_file_from_url(tif_url, download_path):\n",
    "    \"\"\"Function to download a file if it's a URL\"\"\"\n",
    "    if tif_url.startswith(\"http\"):\n",
    "        response = requests.get(tif_url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            with open(download_path, \"wb\") as out_file:\n",
    "                out_file.write(response.content)\n",
    "        else:\n",
    "            print(f\"Failed to download: {tif_url}\")\n",
    "            return None\n",
    "    else:\n",
    "        return tif_url\n",
    "    return download_path\n",
    "\n",
    "\n",
    "def merge_tif_files(folder_path, output_filename):\n",
    "    \"\"\"\n",
    "    Merges all GeoTIFF files in the given folder and saves the merged result.\n",
    "    \n",
    "    Parameters:\n",
    "    - folder_path: str, path to the folder containing GeoTIFF files\n",
    "    - output_filename: str, name of the output merged GeoTIFF file\n",
    "    \"\"\"\n",
    "    # List all files in the folder\n",
    "    tif_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.tif')]\n",
    "    \n",
    "    if not tif_files:\n",
    "        return None\n",
    "    \n",
    "    # Open all GeoTIFF files\n",
    "    src_files_to_mosaic = [rasterio.open(fp) for fp in tif_files]\n",
    "\n",
    "    # Merge the files\n",
    "    mosaic, out_transform = merge(src_files_to_mosaic)\n",
    "\n",
    "    # Write the merged file\n",
    "    merged_tif_path = os.path.join(folder_path, output_filename)\n",
    "    with rasterio.open(\n",
    "        merged_tif_path, \"w\",\n",
    "        driver=\"GTiff\",\n",
    "        height=mosaic.shape[1],\n",
    "        width=mosaic.shape[2],\n",
    "        count=src_files_to_mosaic[0].count,\n",
    "        dtype=src_files_to_mosaic[0].dtypes[0],\n",
    "        crs=src_files_to_mosaic[0].crs,\n",
    "        transform=out_transform\n",
    "    ) as dest:\n",
    "        dest.write(mosaic)\n",
    "    \n",
    "    # Close the files\n",
    "    for src in src_files_to_mosaic:\n",
    "        src.close()\n",
    "    return merged_tif_path\n",
    "\n",
    "merged_tifs = []\n",
    "for year_path in year_paths:\n",
    "    files_in_year_folder = [file for file in os.listdir(year_path) if file.endswith('.txt')]\n",
    "    for txt_file in files_in_year_folder:\n",
    "        txt_path = os.path.join(year_path, txt_file)\n",
    "        print(txt_path)\n",
    "        with open(txt_path, \"r\") as f:\n",
    "            tif_paths = [line.strip() for line in f.readlines()]\n",
    "        for tif_path_mean in tif_paths:\n",
    "            mean_url = f\"http://opendap.biodt.eu/ias-pdt/0/outputs/hab{habitat_number}/predictions/{tif_path_mean}\"\n",
    "            tif_filename = os.path.join(year_path, os.path.basename(mean_url))\n",
    "            downloaded_file = download_file_from_url(mean_url, tif_filename)\n",
    "        year = os.path.basename(year_path)\n",
    "        merged_output_filename = f\"{year}_merged_output.tif\"\n",
    "        merged_tif = merge_tif_files(year_path, merged_output_filename)\n",
    "        merged_tifs.append(merged_tif)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E-Plot Mean\n",
    "print(merged_tifs)\n",
    "frames = []\n",
    "\n",
    "\n",
    "for tif_file in merged_tifs:\n",
    "    print(tif_file)\n",
    "    data_mean = rioxarray.open_rasterio(tif_file)\n",
    "    frames.append(data_mean[0])    \n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "img = frames[0].plot(ax=ax, cmap=\"Spectral\", add_colorbar=True)\n",
    "ax.grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "# Add north arrow\n",
    "ax.annotate( \"N\",\n",
    "    xy=(conf_x, conf_y),\n",
    "    xytext=(conf_x, conf_y - conf_arrow_length),\n",
    "    arrowprops=dict(facecolor=\"black\", width=5, headwidth=15),\n",
    "    ha=\"center\",\n",
    "    va=\"center\",\n",
    "    fontsize=12,\n",
    "    xycoords=ax.transAxes,\n",
    ")\n",
    "\n",
    "# Update function for animation\n",
    "def update(frame_idx):\n",
    "    img.set_array(frames[frame_idx].values)\n",
    "    ax.set_title(\n",
    "        f\"Mean Species Distribution for {param_species_class} in {param_habitat_name} \"\n",
    "        f\"for {param_climate_model}\\nFrame {frame_idx + 1}\"\n",
    "    )\n",
    "    return img\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=len(frames), interval=1000, blit=False)\n",
    "# Save animation\n",
    "output_gif = conf_data_path + os.path.basename(tif_file)\n",
    "ani.save(output_gif, writer=\"pillow\", fps=2)\n",
    "\n",
    "print(f\"Animation saved as {output_gif}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:biodt-hackathon25]",
   "language": "python",
   "name": "conda-env-biodt-hackathon25-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
